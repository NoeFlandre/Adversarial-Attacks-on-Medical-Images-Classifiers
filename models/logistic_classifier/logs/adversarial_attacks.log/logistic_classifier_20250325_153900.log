2025-03-25 15:39:00,086 - INFO - Logging initialized. Log file: /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/logs/adversarial_attacks.log/logistic_classifier_20250325_153900.log
2025-03-25 15:39:00,086 - INFO - Running adversarial attack evaluation with device: mps
2025-03-25 15:39:00,086 - INFO - Loading dataset from data/
2025-03-25 15:39:05,794 - INFO - Test dataset size: 55505
2025-03-25 15:39:05,810 - INFO - Loading model checkpoint from models/logistic_classifier/checkpoints/logistic_regression_model_20250325_142056.pth
2025-03-25 15:39:05,919 - INFO - Running FGSM attack with epsilon=0.01
2025-03-25 15:39:05,939 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-25 15:39:30,397 - INFO - Attack evaluation results:
2025-03-25 15:39:30,400 - INFO -   - Clean Accuracy: 0.7791
2025-03-25 15:39:30,400 - INFO -   - Adversarial Accuracy: 0.0400
2025-03-25 15:39:30,400 - INFO -   - Attack Success Rate: 0.7391
2025-03-25 15:39:30,400 - INFO -   - Attack Success Rate (on correctly classified): 0.7391
2025-03-25 15:39:30,401 - INFO - Saved metrics to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_metrics_eps0.01_20250325_153930.json
2025-03-25 15:39:30,944 - INFO - Saved adversarial examples visualization to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_examples_eps0.01_20250325_153930.png
2025-03-25 15:39:30,945 - INFO - Running FGSM attack with epsilon=0.05
2025-03-25 15:39:30,946 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-25 15:39:49,838 - INFO - Attack evaluation results:
2025-03-25 15:39:49,839 - INFO -   - Clean Accuracy: 0.7791
2025-03-25 15:39:49,839 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-25 15:39:49,839 - INFO -   - Attack Success Rate: 0.7791
2025-03-25 15:39:49,839 - INFO -   - Attack Success Rate (on correctly classified): 0.7791
2025-03-25 15:39:49,839 - INFO - Saved metrics to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_metrics_eps0.05_20250325_153949.json
2025-03-25 15:39:50,060 - INFO - Saved adversarial examples visualization to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_examples_eps0.05_20250325_153949.png
2025-03-25 15:39:50,061 - INFO - Running FGSM attack with epsilon=0.1
2025-03-25 15:39:50,061 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-25 15:40:09,555 - INFO - Attack evaluation results:
2025-03-25 15:40:09,556 - INFO -   - Clean Accuracy: 0.7791
2025-03-25 15:40:09,556 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-25 15:40:09,556 - INFO -   - Attack Success Rate: 0.7791
2025-03-25 15:40:09,556 - INFO -   - Attack Success Rate (on correctly classified): 0.7791
2025-03-25 15:40:09,556 - INFO - Saved metrics to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_metrics_eps0.1_20250325_154009.json
2025-03-25 15:40:09,697 - INFO - Saved adversarial examples visualization to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_examples_eps0.1_20250325_154009.png
2025-03-25 15:40:09,697 - INFO - Running FGSM attack with epsilon=0.2
2025-03-25 15:40:09,698 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-25 15:40:28,655 - INFO - Attack evaluation results:
2025-03-25 15:40:28,656 - INFO -   - Clean Accuracy: 0.7791
2025-03-25 15:40:28,656 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-25 15:40:28,656 - INFO -   - Attack Success Rate: 0.7791
2025-03-25 15:40:28,656 - INFO -   - Attack Success Rate (on correctly classified): 0.7791
2025-03-25 15:40:28,657 - INFO - Saved metrics to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_metrics_eps0.2_20250325_154028.json
2025-03-25 15:40:28,797 - INFO - Saved adversarial examples visualization to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/adversarial/FGSM_examples_eps0.2_20250325_154028.png
