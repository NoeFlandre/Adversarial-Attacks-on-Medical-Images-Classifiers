2025-03-30 11:43:32,297 - INFO - Logging initialized. Log file: /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/logs/model_comparison.log/logistic_classifier_20250330_114332.log
2025-03-30 11:43:32,297 - INFO - Comparing models on device: mps
2025-03-30 11:43:32,297 - INFO - Standard model path: models/logistic_classifier/checkpoints/logistic_regression_model_20250326_210024.pth
2025-03-30 11:43:32,297 - INFO - Adversarial model path: models/logistic_classifier/checkpoints/logistic_regression_adversarial_eps0.05_mix0.5_20250330_113725.pth
2025-03-30 11:43:32,312 - INFO - Standard model: Standard trained
2025-03-30 11:43:32,312 - INFO - Adversarial model: Adversarially trained
2025-03-30 11:43:32,312 - INFO - Adversarial training parameters: epsilon=0.05, mix_ratio=0.5
2025-03-30 11:43:33,838 - INFO - Test dataset size: 55505
2025-03-30 11:44:10,188 - INFO - Clean accuracy - Standard model: 0.7699
2025-03-30 11:44:10,189 - INFO - Clean accuracy - Adversarial model: 0.7720
2025-03-30 11:44:10,189 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 11:44:10,189 - INFO - Evaluating standard model against FGSM (ε=0.01)
2025-03-30 11:44:10,191 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 11:44:29,229 - INFO - Attack evaluation results:
2025-03-30 11:44:29,229 - INFO -   - Clean Accuracy: 0.7699
2025-03-30 11:44:29,229 - INFO -   - Adversarial Accuracy: 0.0449
2025-03-30 11:44:29,229 - INFO -   - Attack Success Rate: 0.7250
2025-03-30 11:44:29,229 - INFO -   - Attack Success Rate (on correctly classified): 0.7250
2025-03-30 11:44:29,230 - INFO - Evaluating adversarial model against FGSM (ε=0.01)
2025-03-30 11:44:29,230 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 11:44:47,809 - INFO - Attack evaluation results:
2025-03-30 11:44:47,810 - INFO -   - Clean Accuracy: 0.7720
2025-03-30 11:44:47,810 - INFO -   - Adversarial Accuracy: 0.7397
2025-03-30 11:44:47,810 - INFO -   - Attack Success Rate: 0.0324
2025-03-30 11:44:47,810 - INFO -   - Attack Success Rate (on correctly classified): 0.0324
2025-03-30 11:44:47,810 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 11:44:47,810 - INFO - Evaluating standard model against FGSM (ε=0.05)
2025-03-30 11:44:47,810 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 11:45:06,312 - INFO - Attack evaluation results:
2025-03-30 11:45:06,312 - INFO -   - Clean Accuracy: 0.7699
2025-03-30 11:45:06,312 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-30 11:45:06,312 - INFO -   - Attack Success Rate: 0.7699
2025-03-30 11:45:06,312 - INFO -   - Attack Success Rate (on correctly classified): 0.7699
2025-03-30 11:45:06,312 - INFO - Evaluating adversarial model against FGSM (ε=0.05)
2025-03-30 11:45:06,313 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 11:45:24,694 - INFO - Attack evaluation results:
2025-03-30 11:45:24,694 - INFO -   - Clean Accuracy: 0.7720
2025-03-30 11:45:24,694 - INFO -   - Adversarial Accuracy: 0.5692
2025-03-30 11:45:24,694 - INFO -   - Attack Success Rate: 0.2028
2025-03-30 11:45:24,694 - INFO -   - Attack Success Rate (on correctly classified): 0.2028
2025-03-30 11:45:24,694 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 11:45:24,694 - INFO - Evaluating standard model against FGSM (ε=0.1)
2025-03-30 11:45:24,695 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 11:45:43,022 - INFO - Attack evaluation results:
2025-03-30 11:45:43,022 - INFO -   - Clean Accuracy: 0.7699
2025-03-30 11:45:43,022 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-30 11:45:43,022 - INFO -   - Attack Success Rate: 0.7699
2025-03-30 11:45:43,022 - INFO -   - Attack Success Rate (on correctly classified): 0.7699
2025-03-30 11:45:43,022 - INFO - Evaluating adversarial model against FGSM (ε=0.1)
2025-03-30 11:45:43,023 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 11:46:02,382 - INFO - Attack evaluation results:
2025-03-30 11:46:02,382 - INFO -   - Clean Accuracy: 0.7720
2025-03-30 11:46:02,382 - INFO -   - Adversarial Accuracy: 0.2152
2025-03-30 11:46:02,382 - INFO -   - Attack Success Rate: 0.5569
2025-03-30 11:46:02,382 - INFO -   - Attack Success Rate (on correctly classified): 0.5569
2025-03-30 11:46:02,382 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 11:46:02,382 - INFO - Evaluating standard model against FGSM (ε=0.2)
2025-03-30 11:46:02,382 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 11:46:20,916 - INFO - Attack evaluation results:
2025-03-30 11:46:20,916 - INFO -   - Clean Accuracy: 0.7699
2025-03-30 11:46:20,916 - INFO -   - Adversarial Accuracy: 0.0000
2025-03-30 11:46:20,916 - INFO -   - Attack Success Rate: 0.7699
2025-03-30 11:46:20,916 - INFO -   - Attack Success Rate (on correctly classified): 0.7699
2025-03-30 11:46:20,916 - INFO - Evaluating adversarial model against FGSM (ε=0.2)
2025-03-30 11:46:20,916 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 11:46:39,276 - INFO - Attack evaluation results:
2025-03-30 11:46:39,277 - INFO -   - Clean Accuracy: 0.7720
2025-03-30 11:46:39,277 - INFO -   - Adversarial Accuracy: 0.0390
2025-03-30 11:46:39,277 - INFO -   - Attack Success Rate: 0.7330
2025-03-30 11:46:39,277 - INFO -   - Attack Success Rate (on correctly classified): 0.7330
2025-03-30 11:46:39,278 - INFO - Results saved to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/comparisons/model_comparison_20250330_114639.json
2025-03-30 11:46:39,436 - INFO - Comparison plot saved to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/logistic_classifier/results/comparisons/model_comparison_plot_20250330_114639.png
