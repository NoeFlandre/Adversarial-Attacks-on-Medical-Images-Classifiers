2025-03-30 13:24:21,594 - INFO - Logging initialized. Log file: /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/lenet/logs/model_comparison.log/lenet_20250330_132421.log
2025-03-30 13:24:21,594 - INFO - Comparing models on device: mps
2025-03-30 13:24:21,594 - INFO - Standard model path: models/lenet/checkpoints/lenet_model_best.pth
2025-03-30 13:24:21,594 - INFO - Adversarial model path: models/lenet/checkpoints/lenet_adv_model_best.pth
2025-03-30 13:24:21,642 - INFO - Standard model: Standard trained
2025-03-30 13:24:21,642 - INFO - Adversarial model: Adversarially trained
2025-03-30 13:24:21,642 - INFO - Adversarial training parameters: epsilon=0.05, mix_ratio=0.5
2025-03-30 13:24:23,169 - INFO - Test dataset size: 55505
2025-03-30 13:25:06,489 - INFO - Clean accuracy - Standard model: 0.8476
2025-03-30 13:25:06,489 - INFO - Clean accuracy - Adversarial model: 0.8300
2025-03-30 13:25:06,489 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 13:25:06,489 - INFO - Evaluating standard model against FGSM (ε=0.01)
2025-03-30 13:25:06,491 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 13:25:36,796 - INFO - Attack evaluation results:
2025-03-30 13:25:36,797 - INFO -   - Clean Accuracy: 0.8476
2025-03-30 13:25:36,797 - INFO -   - Adversarial Accuracy: 0.2329
2025-03-30 13:25:36,797 - INFO -   - Attack Success Rate: 0.6147
2025-03-30 13:25:36,797 - INFO -   - Attack Success Rate (on correctly classified): 0.6147
2025-03-30 13:25:36,797 - INFO - Evaluating adversarial model against FGSM (ε=0.01)
2025-03-30 13:25:36,798 - INFO - Evaluating FGSM attack with epsilon=0.01
2025-03-30 13:26:07,135 - INFO - Attack evaluation results:
2025-03-30 13:26:07,137 - INFO -   - Clean Accuracy: 0.8300
2025-03-30 13:26:07,137 - INFO -   - Adversarial Accuracy: 0.7170
2025-03-30 13:26:07,137 - INFO -   - Attack Success Rate: 0.1132
2025-03-30 13:26:07,137 - INFO -   - Attack Success Rate (on correctly classified): 0.1131
2025-03-30 13:26:07,137 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 13:26:07,137 - INFO - Evaluating standard model against FGSM (ε=0.05)
2025-03-30 13:26:07,138 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 13:26:37,446 - INFO - Attack evaluation results:
2025-03-30 13:26:37,446 - INFO -   - Clean Accuracy: 0.8476
2025-03-30 13:26:37,446 - INFO -   - Adversarial Accuracy: 0.0152
2025-03-30 13:26:37,446 - INFO -   - Attack Success Rate: 0.8324
2025-03-30 13:26:37,446 - INFO -   - Attack Success Rate (on correctly classified): 0.8324
2025-03-30 13:26:37,446 - INFO - Evaluating adversarial model against FGSM (ε=0.05)
2025-03-30 13:26:37,447 - INFO - Evaluating FGSM attack with epsilon=0.05
2025-03-30 13:27:07,908 - INFO - Attack evaluation results:
2025-03-30 13:27:07,908 - INFO -   - Clean Accuracy: 0.8300
2025-03-30 13:27:07,908 - INFO -   - Adversarial Accuracy: 0.6494
2025-03-30 13:27:07,908 - INFO -   - Attack Success Rate: 0.1874
2025-03-30 13:27:07,908 - INFO -   - Attack Success Rate (on correctly classified): 0.1840
2025-03-30 13:27:07,908 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 13:27:07,908 - INFO - Evaluating standard model against FGSM (ε=0.1)
2025-03-30 13:27:07,909 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 13:27:44,301 - INFO - Attack evaluation results:
2025-03-30 13:27:44,301 - INFO -   - Clean Accuracy: 0.8476
2025-03-30 13:27:44,301 - INFO -   - Adversarial Accuracy: 0.0086
2025-03-30 13:27:44,301 - INFO -   - Attack Success Rate: 0.8391
2025-03-30 13:27:44,301 - INFO -   - Attack Success Rate (on correctly classified): 0.8390
2025-03-30 13:27:44,302 - INFO - Evaluating adversarial model against FGSM (ε=0.1)
2025-03-30 13:27:44,302 - INFO - Evaluating FGSM attack with epsilon=0.1
2025-03-30 13:28:17,705 - INFO - Attack evaluation results:
2025-03-30 13:28:17,705 - INFO -   - Clean Accuracy: 0.8300
2025-03-30 13:28:17,705 - INFO -   - Adversarial Accuracy: 0.5382
2025-03-30 13:28:17,705 - INFO -   - Attack Success Rate: 0.3086
2025-03-30 13:28:17,705 - INFO -   - Attack Success Rate (on correctly classified): 0.3002
2025-03-30 13:28:17,705 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 13:28:17,705 - INFO - Evaluating standard model against FGSM (ε=0.2)
2025-03-30 13:28:17,706 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 13:28:50,698 - INFO - Attack evaluation results:
2025-03-30 13:28:50,698 - INFO -   - Clean Accuracy: 0.8476
2025-03-30 13:28:50,698 - INFO -   - Adversarial Accuracy: 0.0197
2025-03-30 13:28:50,698 - INFO -   - Attack Success Rate: 0.8420
2025-03-30 13:28:50,698 - INFO -   - Attack Success Rate (on correctly classified): 0.8349
2025-03-30 13:28:50,698 - INFO - Evaluating adversarial model against FGSM (ε=0.2)
2025-03-30 13:28:50,698 - INFO - Evaluating FGSM attack with epsilon=0.2
2025-03-30 13:29:20,779 - INFO - Attack evaluation results:
2025-03-30 13:29:20,779 - INFO -   - Clean Accuracy: 0.8300
2025-03-30 13:29:20,779 - INFO -   - Adversarial Accuracy: 0.3456
2025-03-30 13:29:20,779 - INFO -   - Attack Success Rate: 0.5239
2025-03-30 13:29:20,779 - INFO -   - Attack Success Rate (on correctly classified): 0.5041
2025-03-30 13:29:20,780 - INFO - Results saved to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/lenet/results/comparisons/model_comparison_20250330_132920.json
2025-03-30 13:29:20,999 - INFO - Comparison plot saved to /Users/noeflandre/Documents/[03] School/École d'ingénieur/3A/IIT Bombay/Courses/Medical Image Computing/Project/Adversarial-Attacks-on-Medical-Images-Classifiers/models/lenet/results/comparisons/model_comparison_plot_20250330_132920.png
