2025-04-18 22:42:35,057 - INFO - Logging initialized. Log file: /Users/noeflandre/Adversarial-Attacks-on-Medical-Images-Classifiers/models/tiny_transformer/logs/adversarial_attacks.log/transformer_20250418_224235.log
2025-04-18 22:42:35,057 - INFO - Running adversarial attack evaluation with device: mps
2025-04-18 22:42:35,057 - INFO - Loading dataset from data/
2025-04-18 22:42:35,787 - INFO - Test dataset size: 55505
2025-04-18 22:42:35,799 - INFO - Tiny Transformer parameters: 181,442 (0.18M)
2025-04-18 22:42:35,799 - INFO - Loading model checkpoint from models/tiny_transformer/checkpoints/tiny_transformer_model_20250410_114945.pth
2025-04-18 22:42:35,828 - INFO - Running DeepFool attack with max_iter=50, overshoot=0.02
2025-04-18 22:42:35,830 - INFO - Evaluating DeepFool attack
2025-04-18 23:08:20,053 - INFO - Attack evaluation results:
2025-04-18 23:08:20,056 - INFO -   - Clean Accuracy: 0.7827
2025-04-18 23:08:20,056 - INFO -   - Adversarial Accuracy: 0.0000
2025-04-18 23:08:20,056 - INFO -   - Attack Success Rate: 0.7827
2025-04-18 23:08:20,056 - INFO -   - Attack Success Rate (on correctly classified): 0.7827
2025-04-18 23:08:20,058 - INFO - Saved metrics to /Users/noeflandre/Adversarial-Attacks-on-Medical-Images-Classifiers/models/tiny_transformer/results/adversarial/DeepFool_metrics_over0.02_iter50_20250418_230820.json
2025-04-18 23:08:20,452 - INFO - Saved adversarial examples visualization to /Users/noeflandre/Adversarial-Attacks-on-Medical-Images-Classifiers/models/tiny_transformer/results/adversarial/DeepFool_examples_over0.02_iter50_20250418_230820.png
